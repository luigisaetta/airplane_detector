{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c182b7",
   "metadata": {},
   "source": [
    "### YOLO V8 Plane Detector\n",
    "* using directly YOLO v8 model\n",
    "* process a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a922417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd24df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "# passati a modello large\n",
    "MODEL_PATH = \"./runs/detect/train3/weights/best.pt\"\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# set model parameters\n",
    "# model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides[\"iou\"] = 0.45  # NMS IoU threshold\n",
    "# model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "# model.overrides['max_det'] = 1000\n",
    "\n",
    "# Video in input\n",
    "VIDEO_PATH = \"mixkit-jet1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f287ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO_PATH = \"mixkit-plane-taking-off.mp4\"\n",
    "CODEC = \"mp4v\"\n",
    "\n",
    "ONLY_NAME = VIDEO_PATH.split(\".\")[0]\n",
    "\n",
    "# name of the video with BB\n",
    "VIDEO_OUT = f\"{ONLY_NAME}_bb.mp4\"\n",
    "\n",
    "# settings for the BB that will be added\n",
    "# remember: OpenCV is BGR\n",
    "color = (0, 0, 255)  # red\n",
    "tickness = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05868c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzed input video:\n",
      "\n",
      "Number of frames is: 549\n",
      "Fps are: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for the original video\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = math.ceil(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "print()\n",
    "print(\"Analyzed input video:\")\n",
    "print()\n",
    "print(f\"Number of frames is: {n_frames}\")\n",
    "print(f\"Fps are: {fps}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244f03d",
   "metadata": {},
   "source": [
    "#### Apply YOLO to single frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7de1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input video mixkit-jet1.mp4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [00:14<00:00, 39.13it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing input video {VIDEO_PATH}...\")\n",
    "print()\n",
    "\n",
    "# read the first frame and initialize\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# take height, width from the first frame\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# the annotated (output) video\n",
    "video = cv2.VideoWriter(VIDEO_OUT, cv2.VideoWriter_fourcc(*CODEC), fps, (width, height))\n",
    "\n",
    "# process frame by frame\n",
    "# tqdm for progress bar\n",
    "with tqdm(total=n_frames) as pbar:\n",
    "    while ret:\n",
    "        # apply yolo to the single frame\n",
    "        results = model.predict(frame, verbose=False)\n",
    "\n",
    "        # make a copy to add bb\n",
    "        new_image = frame.copy()\n",
    "\n",
    "        for result in results:\n",
    "            # move to cpu\n",
    "            result = result.cpu()\n",
    "            # cast to int\n",
    "            boxes = result.boxes.xyxy.numpy().astype(int)\n",
    "\n",
    "            for box in boxes:\n",
    "                # add rectangle\n",
    "                new_image = cv2.rectangle(\n",
    "                    new_image, (box[0], box[1]), (box[2], box[3]), color, tickness\n",
    "                )\n",
    "\n",
    "        # write the annotated image in the video\n",
    "        video.write(new_image)\n",
    "\n",
    "        # update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "        # next frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "# close the output\n",
    "video.release()\n",
    "\n",
    "# close the input\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf63a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Process video with YOLO v8 model correctly terminated.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335c511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airplane_detection_env_v2_0]",
   "language": "python",
   "name": "conda-env-airplane_detection_env_v2_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
